infra:
  exp_name: srh_segmentation      # Experiment name
  comment: 5fold_training         # Run identifier
  log_dir: /path/to/experiments   # Absolute path for logs
  seed: 1000                      # Seed for random number generation
data:
  which: SRHSingleCell            # Dataset type (default SRHSingleCell)
  direct_params:
    common:
      data_root: /path/to/srh550              # Absolute path for images and labels directory
      slides_file: /path/to/srh550_meta.csv   # Absolute path for dataset splits file
      removed_labels:                         # Labels to exclude from dataset
        - axons
        - blood_vessel
        - chromatin
    train:
      folds: [0,1,2,4]            # Training fold indices
    val:
      folds: [3]                  # Validation fold indices
  augmentations:
    base_aug_cf:
      get_third_channel_params:
        mode: three_channels      # SRH image preprocessing method (default three_channels)
        subtracted_base: 5000     # Constant to specify basae intensity for red color channel (default 5000)
    train_strong_aug_cf:
      p: 0                        # Likelihood of applying each training augmentation
      augs: []                    # List of training augmentations (options listed in `get_strong_aug` function in `ds/datasets/db_improc.py`)
    val_strong_aug_cf:            # Can use `same` to copy train_strong_aug_cf values
      p: 0                        # Likelihood of applying each validation augmentation
      augs: []                    # List of possible validation augmentations (options same as training augmentations)
loader:
  direct_params:
    common:                       # Shared parameters between training and validation data loaders
      num_workers: 0              # Number of subprocesses for data loading
      batch_size: 8               # Number of data samples in each batch
      drop_last: False            # Discard final batch if fewer samples than batch size 
      shuffle: False              # Shuffle dataset before splitting into batches

model:
  name: mrcnn                     # Model type to train (default mrcnn)

eval:
  ckpt_path: relative/path/to/checkpoint.ckpt   # Relative path to model checkpoint (formatted `run_timestamp_seed_comment/models/ckpt.ckpt`)
tune:                             # Create configs for multiple jobs submitted at once, overrides prior configs above
  diagonal_items: true            # Disable running all combinations of `tune/params`
  params:
    eval/ckpt_path:                   # Tune task relative paths to model checkpoints
    - relative/path/to/fold0/checkpoint.ckpt
    - relative/path/to/fold1/checkpoint.ckpt
    - relative/path/to/fold2/checkpoint.ckpt
    - relative/path/to/fold3/checkpoint.ckpt
    - relative/path/to/fold4/checkpoint.ckpt
    - relative/path/to/fold_all/checkpoint.ckpt
    infra/comment:                    # Tune task comments
    - dev_fold_0
    - dev_fold_1
    - dev_fold_2
    - dev_fold_3
    - dev_fold_4
    - dev_fold_all
    data/direct_params/train/folds:   # Tune task training folds
    - [1,2,3,4]
    - [0,2,3,4]
    - [0,1,3,4]
    - [0,1,2,4]
    - [0,1,2,3]
    - [0,1,2,3,4]
    data/direct_params/val/folds:     # Tune task validation folds
    - [0]
    - [1]
    - [2]
    - [3]
    - [4]
    - [0,1,2,3,4]
